
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="../../..">
      
      
        <link rel="next" href="../../open-webui-rag/open-webui-rag/">
      
      
      <link rel="icon" href="../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.14">
    
    
      
        <title>Build Your Local AI. From Zero to a Custom ChatGPT Interface with Ollama & Open WebUI - phautelman</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.342714a4.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
   <link href="../../../assets/stylesheets/glightbox.min.css" rel="stylesheet"/><style>
    html.glightbox-open { overflow: initial; height: 100%; }
    .gslide-title { margin-top: 0px; user-select: text; }
    .gslide-desc { color: #666; user-select: text; }
    .gslide-image img { background: white; }
    .gscrollbar-fixer { padding-right: 15px; }
    .gdesc-inner { font-size: 0.75rem; }
    body[data-md-color-scheme="slate"] .gdesc-inner { background: var(--md-default-bg-color);}
    body[data-md-color-scheme="slate"] .gslide-title { color: var(--md-default-fg-color);}
    body[data-md-color-scheme="slate"] .gslide-desc { color: var(--md-default-fg-color);}</style> <script src="../../../assets/javascripts/glightbox.min.js"></script></head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#build-your-local-ai-from-zero-to-a-custom-chatgpt-interface-with-ollama-open-webui" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../.." title="phautelman" class="md-header__button md-logo" aria-label="phautelman" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            phautelman
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Build Your Local AI. From Zero to a Custom ChatGPT Interface with Ollama & Open WebUI
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to system preference"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to system preference" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="phautelman" class="md-nav__button md-logo" aria-label="phautelman" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    phautelman
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" checked>
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Tutorials
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Tutorials
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_1" checked>
        
          
          <label class="md-nav__link" for="__nav_2_1" id="__nav_2_1_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Open WebUI
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_1_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2_1">
            <span class="md-nav__icon md-icon"></span>
            Open WebUI
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    Build Your Local AI. From Zero to a Custom ChatGPT Interface with Ollama & Open WebUI
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    Build Your Local AI. From Zero to a Custom ChatGPT Interface with Ollama & Open WebUI
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#toolstack-overview" class="md-nav__link">
    <span class="md-ellipsis">
      Toolstack Overview
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Toolstack Overview">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ollama" class="md-nav__link">
    <span class="md-ellipsis">
      Ollama
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#openwebui" class="md-nav__link">
    <span class="md-ellipsis">
      OpenWebUI
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#requirements" class="md-nav__link">
    <span class="md-ellipsis">
      Requirements
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#environment-setup" class="md-nav__link">
    <span class="md-ellipsis">
      Environment Setup
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Environment Setup">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#setting-up-python-311" class="md-nav__link">
    <span class="md-ellipsis">
      Setting Up Python 3.11
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Setting Up Python 3.11">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#for-macos-users" class="md-nav__link">
    <span class="md-ellipsis">
      For macOS users:
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#installing-and-configuring-ollama" class="md-nav__link">
    <span class="md-ellipsis">
      Installing and Configuring Ollama
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#installing-and-configuring-open-webui" class="md-nav__link">
    <span class="md-ellipsis">
      Installing and Configuring Open WebUI
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#basic-openwebui-functionality" class="md-nav__link">
    <span class="md-ellipsis">
      Basic OpenWebUI Functionality
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Basic OpenWebUI Functionality">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#enabling-web-search" class="md-nav__link">
    <span class="md-ellipsis">
      Enabling Web Search
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Enabling Web Search">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#google-pse-api-setup" class="md-nav__link">
    <span class="md-ellipsis">
      Google PSE API Setup
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#brave-search-api" class="md-nav__link">
    <span class="md-ellipsis">
      Brave Search API
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#test-search-functionality" class="md-nav__link">
    <span class="md-ellipsis">
      Test Search Functionality
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#code-interpreter" class="md-nav__link">
    <span class="md-ellipsis">
      Code Interpreter
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#creating-a-basic-custom-model" class="md-nav__link">
    <span class="md-ellipsis">
      Creating a Basic Custom Model
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#conclusion-next-steps" class="md-nav__link">
    <span class="md-ellipsis">
      Conclusion &amp; Next Steps
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Conclusion &amp; Next Steps">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#what-weve-accomplished" class="md-nav__link">
    <span class="md-ellipsis">
      What We’ve Accomplished
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#next-steps" class="md-nav__link">
    <span class="md-ellipsis">
      Next Steps
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../open-webui-rag/open-webui-rag/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Supercharge Your Local AI with RAG and Custom Knowledge Bases
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../open-webui-action-tools/open-webui-action-tools/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Beyond Text. Equipping Your Open WebUI AI with Action Tools
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_2" >
        
          
          <label class="md-nav__link" for="__nav_2_2" id="__nav_2_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Software
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_2">
            <span class="md-nav__icon md-icon"></span>
            Software
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../effective-software-testing/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Effective Software Testing
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../java-reactive/java-reactive/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Java Reactive Programming Walkthrough - Project Reactor
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Software Tools
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Software Tools
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pahautelman.github.io/mcdc-calculator/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    MC/DC Calculator
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pahautelman.github.io/interactive-fish-cluser/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Interactive Fish Cluster
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#toolstack-overview" class="md-nav__link">
    <span class="md-ellipsis">
      Toolstack Overview
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Toolstack Overview">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ollama" class="md-nav__link">
    <span class="md-ellipsis">
      Ollama
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#openwebui" class="md-nav__link">
    <span class="md-ellipsis">
      OpenWebUI
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#requirements" class="md-nav__link">
    <span class="md-ellipsis">
      Requirements
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#environment-setup" class="md-nav__link">
    <span class="md-ellipsis">
      Environment Setup
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Environment Setup">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#setting-up-python-311" class="md-nav__link">
    <span class="md-ellipsis">
      Setting Up Python 3.11
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Setting Up Python 3.11">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#for-macos-users" class="md-nav__link">
    <span class="md-ellipsis">
      For macOS users:
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#installing-and-configuring-ollama" class="md-nav__link">
    <span class="md-ellipsis">
      Installing and Configuring Ollama
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#installing-and-configuring-open-webui" class="md-nav__link">
    <span class="md-ellipsis">
      Installing and Configuring Open WebUI
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#basic-openwebui-functionality" class="md-nav__link">
    <span class="md-ellipsis">
      Basic OpenWebUI Functionality
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Basic OpenWebUI Functionality">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#enabling-web-search" class="md-nav__link">
    <span class="md-ellipsis">
      Enabling Web Search
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Enabling Web Search">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#google-pse-api-setup" class="md-nav__link">
    <span class="md-ellipsis">
      Google PSE API Setup
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#brave-search-api" class="md-nav__link">
    <span class="md-ellipsis">
      Brave Search API
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#test-search-functionality" class="md-nav__link">
    <span class="md-ellipsis">
      Test Search Functionality
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#code-interpreter" class="md-nav__link">
    <span class="md-ellipsis">
      Code Interpreter
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#creating-a-basic-custom-model" class="md-nav__link">
    <span class="md-ellipsis">
      Creating a Basic Custom Model
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#conclusion-next-steps" class="md-nav__link">
    <span class="md-ellipsis">
      Conclusion &amp; Next Steps
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Conclusion &amp; Next Steps">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#what-weve-accomplished" class="md-nav__link">
    <span class="md-ellipsis">
      What We’ve Accomplished
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#next-steps" class="md-nav__link">
    <span class="md-ellipsis">
      Next Steps
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  



<h1 id="build-your-local-ai-from-zero-to-a-custom-chatgpt-interface-with-ollama-open-webui">Build Your Local AI: From Zero to a Custom ChatGPT Interface with Ollama &amp; Open WebUI</h1>
<p><a class="glightbox" href="../openwebui-frog-master.webp" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="" src="../openwebui-frog-master.webp" /></a></p>
<p>Imagine having ChatGPT or DeepSeek-like capabilities right on your computer — no subscription fees, no privacy concerns, no waiting for responses, and complete customization options. Sounds too good to be true? <strong>It’s not!</strong></p>
<p>Large Language Models (LLMs) have become indispensable tools for many of us. Whether you’re using them to process text, learn new concepts, generate code solutions, automate workflows, or enjoy chatting with your computer buddy — they’re changing how we work and create.</p>
<p>But there’s a catch with popular services like OpenAI, Anthropic, or Perplexity: they often come with limitations:</p>
<ul>
<li><strong>Cost</strong>: Monthly subscriptions or per-token pricing can add up quickly </li>
<li><strong>Limited APIs</strong>: Restricted customization options </li>
<li><strong>Missing features</strong>: Many don’t offer RAG (Retrieval-Augmented Generation) capabilities </li>
<li><strong>Privacy concerns</strong>: Your data might be used for training or stored on third-party servers </li>
<li><strong>Response delays</strong>: Peak usage times can mean long waits for responses </li>
</ul>
<p><strong>The solution?</strong> A locally running LLM instance that you can fully customize to your specific needs — complete with a user-friendly interface that rivals commercial offerings.</p>
<p><strong>In this guide (about a 1-hour setup)</strong>, I’ll walk you through setting up a robust local AI environment using free, open-source tools that provide:</p>
<ul>
<li>Total privacy (your data stays on your machine)</li>
<li>No subscription costs</li>
<li>Minimal response waiting time</li>
<li>Nearly comparable results to high-end commercial LLMs</li>
<li>Complete customizability for your specific use cases</li>
</ul>
<blockquote>
<p><em>Personal note: I've been using this setup for two months, and it has cut my monthly AI subscription costs to zero while increasing my productivity. The initial setup time is worth every minute for the long-term benefits.</em></p>
</blockquote>
<h2 id="toolstack-overview">Toolstack Overview</h2>
<p>Our local AI setup will use two primary tools:</p>
<h3 id="ollama">Ollama</h3>
<p><a href="https://github.com/ollama/ollama">Ollama</a> is an open-source framework designed specifically for running LLMs locally. It provides:</p>
<ul>
<li>Access to a wide variety of open-source models (DeepSeek, Llama, Phi, Mistral, Gemma, and many more)</li>
<li>Text generation capabilities</li>
<li>Multimodal support (for models that can process images)</li>
<li>Efficient model management</li>
</ul>
<h3 id="openwebui">OpenWebUI</h3>
<p><a href="https://github.com/open-webui/open-webui">OpenWebUI</a> is currently the most prominent open-source project offering a UI interface for your Ollama instance. Think of it as your local version of the ChatGPT or Claude interface, but with even more features:</p>
<ul>
<li>User-friendly chat interface</li>
<li>Model customization</li>
<li>RAG capabilities</li>
<li>Web search integration</li>
<li>Code interpreter</li>
<li>Complex workflow design</li>
<li>And many more features are being actively developed</li>
</ul>
<p>The best part? OpenWebUI is constantly improving as passionate engineers contribute to this open-source project, bringing features from proprietary platforms to this free alternative.</p>
<h3 id="requirements">Requirements</h3>
<p>Before we start, make sure your system meets these minimum requirements:</p>
<ul>
<li>A GPU-powered laptop or desktop (minimum 4GB GPU memory, 8GB+ recommended)</li>
<li>At least 20GB of free disk space (models can be large)</li>
<li>A modern web browser</li>
</ul>
<blockquote>
<p><em><strong>Pro tip:</strong> While CPU-only setups technically work, they’ll be significantly slower. Even a modest GPU will greatly improve your experience.</em></p>
</blockquote>
<h2 id="environment-setup">Environment Setup</h2>
<h3 id="setting-up-python-311">Setting Up Python 3.11</h3>
<p>Ollama and OpenWebUI work best with Python 3.11, so we’ll start by making sure we have the correct version installed.</p>
<p>First, check your current Python version:</p>
<pre><code class="language-unix">python --version
</code></pre>
<p><a class="glightbox" href="../python-version.webp" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="&gt; Python 3.13.2" src="../python-version.webp" /></a></p>
<p><em>If you don’t have Python 3.11</em>, we’ll install it using <a href="https://github.com/pyenv/pyenv">pyenv</a>, an excellent tool for managing multiple Python versions:</p>
<blockquote>
<p><em><strong>Note</strong>: Visit the <a href="https://github.com/pyenv/pyenv">pyenv GitHub repository</a> for detailed installation instructions specific to your OS.</em></p>
</blockquote>
<h4 id="for-macos-users">For macOS users:</h4>
<p><strong>1. Install pyenv</strong></p>
<pre><code class="language-unix">brew update
brew install pyenv
</code></pre>
<p><strong>2. Configure your shell</strong>
Add these lines to your shell configuration file (<code>.bashrc</code>, <code>.zshrc</code>, or equivalent):</p>
<pre><code class="language-unix">export PYENV_ROOT=&quot;$HOME/.pyenv&quot;
export PATH=&quot;$PYENV_ROOT/bin:$PATH&quot;
eval &quot;$(pyenv init --path)&quot;
eval &quot;$(pyenv init -)&quot;
</code></pre>
<p>Then reload your shell:</p>
<pre><code class="language-unix">exec &quot;$SHELL&quot;
</code></pre>
<p><strong>3. Install Python 3.11</strong></p>
<pre><code class="language-unix">pyenv install 3.11
</code></pre>
<p><strong>4. Set it as your global Python version</strong></p>
<p>This step is optional but is recommended for quickly starting Ollama and Open WebUI from your terminal in future sessions.</p>
<pre><code class="language-unix">pyenv global 3.11
</code></pre>
<p><strong>5. Verify the installation</strong></p>
<pre><code class="language-unix">python --version
</code></pre>
<p>You should see an output confirming Python 3.11.8 is now installed.</p>
<p><a class="glightbox" href="../updated-python-version.webp" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="&gt; Python 3.11.11" src="../updated-python-version.webp" /></a></p>
<h2 id="installing-and-configuring-ollama">Installing and Configuring Ollama</h2>
<p>Now that we have our Python environment ready let’s install <a href="https://github.com/ollama/ollama">Ollama</a>:</p>
<p><strong>1. Download and Install Ollama</strong></p>
<blockquote>
<p><em><strong>Note:</strong> Visit the Ollama GitHub page and follow the installation instructions for your OS.</em></p>
</blockquote>
<p><em>For macOS users</em>, download the .zip package from the Ollama official repository, unzip the file and install it by clicking the ‘Ollama’ application file.</p>
<p><a class="glightbox" href="../download-ollama.webp" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="" src="../download-ollama.webp" /></a></p>
<p><strong>2. Verify Ollama Installation</strong></p>
<p>Open a terminal/command prompt and type:</p>
<pre><code class="language-unix">ollama
</code></pre>
<p>You should see Ollama startup with a help message indicating it’s running.</p>
<p><a class="glightbox" href="../ollama-start.webp" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="ollama" src="../ollama-start.webp" /></a></p>
<p><strong>3. Exploring Available Models</strong></p>
<p>Ollama gives you access to many open-source models. You can browse available models at <a href="https://ollama.com/search">ollama.com/search</a>.</p>
<p>When selecting a model, consider:</p>
<ul>
<li><strong>Model size</strong> (smaller models run faster but may be less capable)</li>
<li><strong>Specialization</strong> (some models excel at coding, others at creative writing)</li>
<li><strong>Memory requirements</strong> (larger models need more GPU memory)</li>
</ul>
<p>Check the <a href="https://huggingface.co/spaces/open-llm-leaderboard/open_llm_leaderboard#/?official=true">HuggingFace Open LLM Leaderboard</a> for benchmarks and performance metrics. Use the advanced filters and metrics to find suitable models for your task.</p>
<p><a class="glightbox" href="../huggingface-open-leaderboard.webp" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="" src="../huggingface-open-leaderboard.webp" /></a></p>
<blockquote>
<p><em><strong>Pro tip</strong>: Start with smaller models (7B parameters or less) and move to larger ones only if needed. Many tasks can be handled effectively by smaller models, which run much faster.</em></p>
</blockquote>
<p><strong>4. Running Your First Model</strong>
Let’s start with phi4-mini, a small but capable model:</p>
<pre><code class="language-unix">ollama run phi4-mini
</code></pre>
<p>This will download the model (if it’s not already downloaded) and start an interactive chat session. Try asking it a question to verify everything is working.</p>
<p>To exit the chat, type <code>/bye</code> or press Ctrl+D.</p>
<p><a class="glightbox" href="../run-phi4.webp" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="ollama run phi4" src="../run-phi4.webp" /></a></p>
<blockquote>
<p><em><strong>Speed check</strong>: For a smooth experience, a good rule of thumb is that your model should output at least 10–20 words per second. If it’s much slower, you might try a smaller model or check if your GPU is properly utilized.</em></p>
</blockquote>
<figure>
    <a class="glightbox" href="../too-slow.gif" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="" src="../too-slow.gif" /></a>
    <figcaption style="margin-top:0.5em;">
    Too slow!
    </figcaption>
</figure>
<figure>
    <a class="glightbox" href="../good-enoug-speed.gif" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="alt text" src="../good-enoug-speed.gif" /></a>
    <figcaption style="text-align: center; margin-top:0.5em;">
    Good enough!
    </figcaption>
</figure>
<p><strong>5. Check Your Installed Models</strong></p>
<p>List all your installed models with:</p>
<pre><code class="language-unix">ollama list
</code></pre>
<h2 id="installing-and-configuring-open-webui">Installing and Configuring Open WebUI</h2>
<p>Now that Ollama is running, let’s install <a href="https://github.com/open-webui/open-webui">Open WebUI</a> to create a user-friendly interface.</p>
<p><strong>1. Install Open WebUI</strong></p>
<p>The easiest way to install Open WebUI is using pip:</p>
<pre><code class="language-unix">pip install open-webui
</code></pre>
<p><strong>2. Start OpenWebUI</strong></p>
<p>Make sure Ollama is running, then start Open WebUI with:</p>
<pre><code class="language-unix">open-webui serve
</code></pre>
<p><a class="glightbox" href="../openwebui-serve.webp" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="open-webui-serve" src="../openwebui-serve.webp" /></a></p>
<blockquote>
<p><em>Note: Make sure that no other processes are using ports 8080 or 5173</em></p>
</blockquote>
<p><strong>3. Access the UI</strong></p>
<p>Open your web browser and navigate to: <a href="http://localhost:8080/">http://localhost:8080/</a></p>
<p>You should see the OpenWebUI interface welcoming you!</p>
<p><strong>4. Interface Overview</strong></p>
<p>Take a moment to familiarize yourself with the interface:</p>
<ul>
<li><strong>Chat Interface</strong>: The main area where you’ll interact with your AI</li>
<li><strong>Models Menu</strong>: Select which model(s) to use</li>
<li><strong>Chat Controls</strong>: Configure system prompts and model parameters</li>
<li><strong>Settings</strong>: Access administrative features and customizations</li>
</ul>
<p><a class="glightbox" href="../openwebui-settings.webp" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="" src="../openwebui-settings.webp" /></a></p>
<blockquote>
<p><em><strong>Pro tip</strong>: You can even use multiple models in a chat simultaneously to compare responses and aggregate their knowledge.</em></p>
</blockquote>
<p><a class="glightbox" href="../openwebui-multi-response.webp" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="" src="../openwebui-multi-response.webp" /></a></p>
<h2 id="basic-openwebui-functionality">Basic OpenWebUI Functionality</h2>
<p>Let’s explore some of the powerful features of OpenWebUI.</p>
<h3 id="enabling-web-search">Enabling Web Search</h3>
<p>Web search allows your AI to access current information beyond its training data. OpenWebUI supports multiple search engines, giving you flexibility based on your needs. Here’s how to set it up:</p>
<ol>
<li>Go to Settings → Admin Panel → Web Search</li>
<li>Enable web search and select your preferred search engine</li>
</ol>
<p><a class="glightbox" href="../openwebui-enable-search.gif" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="" src="../openwebui-enable-search.gif" /></a></p>
<p>I’ll focus on two popular options: Google PSE and Brave Search. Each has its advantages and disadvantages:</p>
<h4 id="google-pse-api-setup">Google PSE API Setup</h4>
<p><strong>Advantages:</strong></p>
<ul>
<li>King of search. Industry-leading search capabilities and relevance</li>
<li>Generous free tier (10,000 requests per day)</li>
<li>Comprehensive search results across the entire web</li>
</ul>
<p><strong>Disadvantages:</strong></p>
<ul>
<li>Privacy concerns (Google processes your queries 😢)</li>
<li>More complex setup process</li>
</ul>
<p><strong>Setup process:</strong></p>
<p>For detailed instructions on how to set up Google PSE, please refer to the <a href="https://docs.openwebui.com/tutorials/web-search/google-pse/">Open WebUI documentation</a>.</p>
<h4 id="brave-search-api">Brave Search API</h4>
<p><strong>Advantages</strong>:</p>
<ul>
<li>Privacy-focused (doesn’t track your search queries)</li>
<li>Independent search index (not relying on Google)</li>
<li>Simple setup process</li>
<li>Free tier available</li>
</ul>
<p><strong>Disadvantages</strong>:</p>
<ul>
<li>Limited to 2,000 free queries per month</li>
<li>Search results may sometimes be less comprehensive than Google</li>
</ul>
<p><strong>Setup Process</strong>:</p>
<ol>
<li>Go to <a href="https://brave.com/search/api/">Brave Search API</a></li>
<li>Sign up and verify your email</li>
<li>
<p>Navigate to the “Subscribe” tab and choose the free subscription (requires card information)</p>
<p><a class="glightbox" href="../brave-browser-plans.webp" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="" src="../brave-browser-plans.webp" /></a></p>
</li>
<li>
<p>Go to the “API Keys” tab and create a new API key</p>
<p><a class="glightbox" href="../brave-browser-api-keys.webp" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="" src="../brave-browser-api-keys.webp" /></a></p>
</li>
<li>
<p>Copy the token and paste it into Open WebUI’s web search configuration</p>
<p><a class="glightbox" href="../openwebui-use-brave-api.webp" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="" src="../openwebui-use-brave-api.webp" /></a></p>
</li>
</ol>
<h3 id="test-search-functionality">Test Search Functionality</h3>
<p>We can now test the search functionality by asking our AI agent for the weather forecast for this weekend.</p>
<p><a class="glightbox" href="../openwebui-search-func.webp" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="" src="../openwebui-search-func.webp" /></a></p>
<blockquote>
<p><em><strong>Note</strong>: Only enable web search when you need recent information or are researching topics outside the model’s knowledge, as it significantly slows down response time. For most general queries, the built-in knowledge of your model will be faster and sufficient.</em></p>
</blockquote>
<h3 id="code-interpreter">Code Interpreter</h3>
<p>Open WebUI’s code interpreter transforms your AI assistant into a dynamic programming tool, enabling it to write and execute Python code directly within the chat interface.</p>
<blockquote>
<p><em><strong>Why This Matters</strong>: Your AI can now solve problems with code, demonstrate processes, and allow you to modify solutions interactively.</em></p>
</blockquote>
<p><strong>Key Features:</strong></p>
<ul>
<li><strong>Interactive Code Blocks</strong>: <em>View</em> and <em>edit</em> AI-generated code directly in your chat.</li>
<li><strong>Multiple Executions</strong>: Run code multiple times with different inputs.</li>
<li><strong>Real-time Feedback</strong>: Receive immediate results without switching platforms.</li>
<li><strong>No Execution Limits</strong>: Enjoy unrestricted code execution without arbitrary limits.</li>
</ul>
<p>When you request a task that benefits from computational assistance, the AI recognizes the need for code execution and generates appropriate Python code that helps it answer your query. Just make sure to enable the ‘Code Interpreter’ option in your chat.</p>
<p><strong>Enabling the Code Interpreter</strong>:</p>
<ol>
<li>Navigate to Settings → Admin Panel → Code Execution.</li>
<li>Toggle the “Enable Code Interpreter” switch to <strong>On</strong>.</li>
</ol>
<p><a class="glightbox" href="../openwebui-enable-interpreter.gif" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="" src="../openwebui-enable-interpreter.gif" /></a></p>
<p><strong>Example Use Case:</strong></p>
<p>Imagine you need to find the prime factorization of a large number. This task can be challenging for humans to perform quickly and accurately, and it can also be difficult for AI assistants. That’s why we seek the assistance of a computer to help with this task.</p>
<p>Proompt:
<code>what is the prime factors decomposition of 272894?</code></p>
<p>Without Code Interpreter:</p>
<figure>
    <a class="glightbox" href="../openwebui-without-interpreter.webp" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="" src="../openwebui-without-interpreter.webp" /></a>
    <figcaption style="text-align: center; margin-top:0.5em;">
    Headache-inducing, isn’t it?
    </figcaption>
</figure>
<p>With Code Interpreter:</p>
<figure>
    <a class="glightbox" href="../openwebui-with-interpreter.webp" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="" src="../openwebui-with-interpreter.webp" /></a>
    <figcaption style="text-align: center; margin-top:0.5em;">
    ^_^
    </figcaption>
</figure>
<p>The code interpreter fundamentally changes how you interact with your AI, transforming it from a conversational assistant into a computational powerhouse that can directly solve problems and demonstrate solutions. <em>This feature alone can justify the entire local setup process</em> for many users, especially those with data analysis, programming, or mathematics.</p>
<h3 id="creating-a-basic-custom-model">Creating a Basic Custom Model</h3>
<p>One of the most powerful features of Open WebUI is the ability to customize how your AI behaves. To unlock this feature:</p>
<ol>
<li>Go to Workspace → Models → Create New</li>
<li>Select your model a name, and select a base model (e.g., phi4-mini)</li>
<li>Customize its behaviour (e.g., by adding a system prompt guiding its behaviour)</li>
</ol>
<p><a class="glightbox" href="../openwebui-custom-model.gif" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="" src="../openwebui-custom-model.gif" /></a></p>
<p>For example, you could create a biology professor persona with this system prompt:</p>
<pre><code class="language-txt">You are a university professor specialising in Biology with a passion for frogs-and you have a charming lisp in your speech. When interacting with users:

- Answer biology-related queries with clear, factual, and detailed explanations, mainly focusing on frog topics.
- Explain complex concepts using analogies drawn from everyday scenarios, making them easier to grasp.
- If a user's question is ambiguous or unclear, ask clarifying questions before providing a complete answer.
- Regularly quiz the user on key points to confirm understanding.
- Propose various follow-up questions or alternative learning directions to encourage further discussion.
- Maintain a friendly, engaging, and scholarly tone, ensuring your unique lisp is reflected in your speech.'
</code></pre>
<p>To get such wonderful AI assistant interactions:</p>
<p><a class="glightbox" href="../openwebui-custom-model-reply.webp" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="" src="../openwebui-custom-model-reply.webp" /></a></p>
<blockquote>
<p><em><strong>Pro tip</strong>: Create different model configurations for different tasks — one for brainstorming, another for coding, and yet another for detailed explanations.</em></p>
</blockquote>
<h2 id="conclusion-next-steps">Conclusion &amp; Next Steps</h2>
<p>Congratulations! 🎉 You now have a fully functional local AI environment that gives you:</p>
<ul>
<li>Privacy (your data stays on your machine)</li>
<li>Cost savings (no subscription fees)</li>
<li>Fast responses</li>
<li>Customizable AI assistants</li>
</ul>
<p>In just about an hour, you’ve set up an infrastructure that rivals commercial AI platforms, all while maintaining complete control over your data and experience.</p>
<h3 id="what-weve-accomplished">What We’ve Accomplished</h3>
<ul>
<li>✅ Set up the required Python environment</li>
<li>✅ Installed and configured Ollama</li>
<li>✅ Installed and set up OpenWebUI</li>
<li>✅ Enabled web search capabilities</li>
<li>✅ Activated the code interpreter</li>
<li>✅ Created a basic custom model</li>
</ul>
<h3 id="next-steps">Next Steps</h3>
<p>If you want to advance your project or learn more about Retrieval-Augmented Generation (RAG) and custom knowledge bases, check out the next article: "Open WebUI Tutorial — Supercharge Your Local AI with RAG and Custom Knowledge Bases". This guide walks you through the out-of-the-box RAG features in Open WebUI that require no coding. By the end of the tutorial, you’ll be able to build your own local documentation assistant.</p>
<!-- 
## Commands

* `mkdocs new [dir-name]` - Create a new project.
* `mkdocs serve` - Start the live-reloading docs server.
* `mkdocs build` - Build the documentation site.
* `mkdocs -h` - Print help message and exit.
![alt text](https://miro.medium.com/v2/resize%3Afit%3A1400/format%3Awebp/1%2A3AsuQ6_6Jd5JxUaff31urw.gif)
## Project layout

    mkdocs.yml    # The configuration file.
    docs/
        index.md  # The documentation homepage.
        ...       # Other markdown pages, images and other files. -->












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "../../..", "features": [], "search": "../../../assets/javascripts/workers/search.d50fe291.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../../assets/javascripts/bundle.13a4f30d.min.js"></script>
      
    
  <script id="init-glightbox">const lightbox = GLightbox({"touchNavigation": true, "loop": false, "zoomable": true, "draggable": true, "openEffect": "zoom", "closeEffect": "zoom", "slideEffect": "slide"});
document$.subscribe(() => { lightbox.reload() });
</script></body>
</html>